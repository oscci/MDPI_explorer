[
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "A dataframe with 430 journal titles and their respective sitemap codes.\n\n\n\n\n\n\nNote\n\n\n\nLast update: December 2023\n\n\n\nMDPI_journals|&gt;\n  head(10)\n\n                               name            code\n1                         Acoustics       acoustics\n2                         Actuators       actuators\n3           Administrative Sciences          admsci\n4                       Adolescents     adolescents\n5  Advances in Respiratory Medicine             arm\n6                       Aerobiology     aerobiology\n7                         Aerospace       aerospace\n8                       Agriculture     agriculture\n9                   AgriEngineering agriengineering\n10                    Agrochemicals   agrochemicals"
  },
  {
    "objectID": "datasets.html#mdpi_journals",
    "href": "datasets.html#mdpi_journals",
    "title": "Datasets",
    "section": "",
    "text": "A dataframe with 430 journal titles and their respective sitemap codes.\n\n\n\n\n\n\nNote\n\n\n\nLast update: December 2023\n\n\n\nMDPI_journals|&gt;\n  head(10)\n\n                               name            code\n1                         Acoustics       acoustics\n2                         Actuators       actuators\n3           Administrative Sciences          admsci\n4                       Adolescents     adolescents\n5  Advances in Respiratory Medicine             arm\n6                       Aerobiology     aerobiology\n7                         Aerospace       aerospace\n8                       Agriculture     agriculture\n9                   AgriEngineering agriengineering\n10                    Agrochemicals   agrochemicals"
  },
  {
    "objectID": "datasets.html#agriculture",
    "href": "datasets.html#agriculture",
    "title": "Datasets",
    "section": "Agriculture",
    "text": "Agriculture\nA dataframe with information of papers of the journal MDPI Agriculture\n\n\n\n\n\n\nNote\n\n\n\nLast update: December 2023\n\n\n\nagriculture|&gt;\n  head(5)\n\n                                        i article_type   Received   Accepted\n1 https://www.mdpi.com/2077-0472/11/5/452      Article 2021-04-01 2021-05-13\n2 https://www.mdpi.com/2077-0472/11/5/453       Review 2021-04-30 2021-05-14\n3 https://www.mdpi.com/2077-0472/11/5/454      Article 2021-04-08 2021-05-16\n4 https://www.mdpi.com/2077-0472/11/5/455      Article 2021-04-08 2021-05-15\n5 https://www.mdpi.com/2077-0472/11/5/456      Article 2021-03-31 2021-05-14\n      tat year    issue_type\n1 42 days 2021            No\n2 14 days 2021 Special Issue\n3 38 days 2021 Special Issue\n4 37 days 2021 Special Issue\n5 44 days 2021 Special Issue"
  },
  {
    "objectID": "datasets.html#horticulturae",
    "href": "datasets.html#horticulturae",
    "title": "Datasets",
    "section": "Horticulturae",
    "text": "Horticulturae\nA dataframe with information of papers of the journal MDPI Horticulturae\n\n\n\n\n\n\nNote\n\n\n\nLast update: December 2023\n\n\n\nhorticulturae|&gt;\n  head(5)\n\n                                         i article_type   Received   Accepted\n1 https://www.mdpi.com/2311-7524/9/12/1295      Article 2023-11-04 2023-11-29\n2   https://www.mdpi.com/2311-7524/7/8/226      Article 2021-07-15 2021-08-02\n3    https://www.mdpi.com/2311-7524/5/1/16      Article 2018-12-26 2019-01-28\n4   https://www.mdpi.com/2311-7524/9/6/706      Article 2023-05-09 2023-06-13\n5    https://www.mdpi.com/2311-7524/8/1/74      Article 2021-11-29 2022-01-07\n      tat year    issue_type\n1 25 days 2023       Section\n2 18 days 2021 Special Issue\n3 33 days 2019 Special Issue\n4 35 days 2023       Section\n5 39 days 2022 Special Issue"
  },
  {
    "objectID": "datasets.html#submit-your-data-set",
    "href": "datasets.html#submit-your-data-set",
    "title": "Datasets",
    "section": "Submit your data set",
    "text": "Submit your data set\nIf you wish to submit your own MDPI journal data set for it to be part of the MDPIexploreR package, the best way is to send/push your articles_info() output via GitHub in .rda format."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MDPIexploreR - A guide",
    "section": "",
    "text": "Ever changing scientific publishing strategies shape academic communications.\nTo date, MDPI is the largest publisher of Open Access articles in the world and top-3 overall publisher (Right after Elsevier and SpringerNature). “The Strain on Scientific Publishing” highlights them as a frequent outlier for several metrics, but also as one of the most transparent major publishers out there.\nThis R package intends to help users to obtain factual data from MDPI’s journals, directly from their website (via web-scraping) and nothing else. A compilation of several functions to explore articles metrics across all MDPI journals and special issues."
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "MDPIexploreR - A guide",
    "section": "",
    "text": "Ever changing scientific publishing strategies shape academic communications.\nTo date, MDPI is the largest publisher of Open Access articles in the world and top-3 overall publisher (Right after Elsevier and SpringerNature). “The Strain on Scientific Publishing” highlights them as a frequent outlier for several metrics, but also as one of the most transparent major publishers out there.\nThis R package intends to help users to obtain factual data from MDPI’s journals, directly from their website (via web-scraping) and nothing else. A compilation of several functions to explore articles metrics across all MDPI journals and special issues."
  },
  {
    "objectID": "index.html#installing-mdpiexplorer",
    "href": "index.html#installing-mdpiexplorer",
    "title": "MDPIexploreR - A guide",
    "section": "Installing MDPIexploreR",
    "text": "Installing MDPIexploreR\n\ndevtools::install_github(\"pgomba/MDPI_explorer\")\nlibrary(MDPIexploreR)\n\n\n\n\n\n\n\nNote\n\n\n\nLast update: December 2023"
  },
  {
    "objectID": "index.html#data-extracting-functions",
    "href": "index.html#data-extracting-functions",
    "title": "MDPIexploreR - A guide",
    "section": "Data extracting functions",
    "text": "Data extracting functions\narticle_find(): The sole purpose of this function is to compile a vector with URLs for the papers of the target journal. Some journals might have more than one sitemap (sitemaps are limited to 50,000 urls), but article_find() is able to solve dual sitemaps. To use the function is only necessary to input a string with the code name of the target journal:\n\nurls&lt;-journal_papers(\"agriculture\")\n\nThe journal code name usually coincides with the journal title, but this is not always the case if the journal name is too long. To find the code name for your journal of interest check the dataset MDPI_journals, included in the package:\n\nMDPI_journals|&gt;\n  head(10)\n\n                               name            code\n1                         Acoustics       acoustics\n2                         Actuators       actuators\n3           Administrative Sciences          admsci\n4                       Adolescents     adolescents\n5  Advances in Respiratory Medicine             arm\n6                       Aerobiology     aerobiology\n7                         Aerospace       aerospace\n8                       Agriculture     agriculture\n9                   AgriEngineering agriengineering\n10                    Agrochemicals   agrochemicals\n\n\narticles_info(): Uses the vector produced by journal_papers() to, by web scraping each URL, obtain a data frame with information on editorial times (when article was received and accepted), turnaround times (time differential between acceptance and submission), data on type of issue where the article was published and type of article. The function allows to include a delay between web scraping instances (I recommend using 2 seconds to avoid having much impact in their servers) and, the possibility of only scraping a sample of all URLs\n\n#Will scrape all url values leaving 2 seconds between iterations\ndata&lt;-articles_info(urls,2) \n\n#Will scrape 1000 random papers from the url vector every 5 seconds\ndata&lt;-articles_info(urls,2,1000)\n\n\n\n\n\n\n\nImportant\n\n\n\nA stable internet connection is recommended, specially for web scraping large numbers of papers"
  },
  {
    "objectID": "index.html#special-issues-guest-editors.",
    "href": "index.html#special-issues-guest-editors.",
    "title": "MDPIexploreR - A guide",
    "section": "Special issues & guest editors.",
    "text": "Special issues & guest editors.\nAs per MDPI Special Issues policy, these “may publish contributions from the Guest Editor(s), but the number of such contributions should be limited to 25%”. The function guest_editor() finds all closed special issues and calculate the proportion of articles with guest editors (prop_flag column) in then, including an option to delay special issues iterations. Additionally, calculates the difference between when the special issue was closed and the publication time of the last accepted article.\n\nguest_editor(\"sustainability\",2)\n\n\n\n\n\n\nThis function is inspired by MA Oviedo-García work on MDPI’s special issues."
  },
  {
    "objectID": "index.html#plotting-functions",
    "href": "index.html#plotting-functions",
    "title": "MDPIexploreR - A guide",
    "section": "Plotting functions",
    "text": "Plotting functions\nThe plotting functions help to summarize the collected data. They only need a data.frame obtained via articles_info() and a string with the name of the journal. Some examples:\n\nsummary_graph(data,\"Agriculture\")\n\n\n\naverage_graph(data,\"Agriculture\")\n\n\n\nissues_graph(data,\"Agriculture\")\n\n\n\ntypes_graph(data,\"Agriculture\")"
  },
  {
    "objectID": "index.html#tips-tricks",
    "href": "index.html#tips-tricks",
    "title": "MDPIexploreR - A guide",
    "section": "Tips & Tricks",
    "text": "Tips & Tricks\n\n\n\n\n\n\nTip\n\n\n\nWeb scraping large amounts of URLs can be time consuming (2 seconds per paper, depending on delay) and many things can go wrong during the process (problematic URLs, being kicked out of the server…). My advice is to split large URL vectors in smaller ones"
  }
]